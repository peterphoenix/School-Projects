{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MID ANN 4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFSW6jXsXajddNRXZW9Cdn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterphoenix/School-Projects/blob/master/MID_ANN_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXGONidvyAzV"
      },
      "source": [
        "Peter Phoenix - 2201735413\n",
        "Artificial Neural Network LA01\n",
        "\n",
        "4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrT2ZzeC1vNq"
      },
      "source": [
        "Time Series Forecasting adalah suatu proses untuk memprediksi hasil berikutnya dari serangkaian urutan kejadian tertentu. Contoh dari time series forecasting adalah saat memprediksi pasar saham. Jika kita terbiasa melihat harga saham yang naik berhari-hari berturut-turut kemudian turun, maka hal inilah yang akan diprediksi oleh Time Series Forecasting. Berdasarkan data yang diinput sebelumnya, proses ini akan mencari kesamaan dari data tersebut. Tentunya hasil prediksi akan berdasarkan dari pola-pola kejadian yang telah diinput sebelumnya.\n",
        "\n",
        "Salah satu cara untuk melakukan Time Series Forecasting adalah dengan menggunakan RNN atau Recurrent Neural Network. RNN mirip dengan Feedforward Neural Network namun setiap output yang dikeluarkan bergantung pada perhitungan sebelumnya. Pada RNN, setelah selesai melakukan perhitungan pada hidden layer, hasil tersebut disalin ulang menuju input kemudian dilakukan perhitungan berulang lagi. Oleh karena itu saat menghasilkan output, hasil tersebut bergantung dengan input sekarang dan output yang pernah dihitung sebelumnya. Karena ini juga seluruh input pada RNN bergantung satu sama lain. Salah satu contoh RNN paling simpel adalah Elman RNN dan Jordan RNN.\n",
        "\n",
        "Berikut dibawah adalah contoh kode mengenai Elman RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJSNXmPfx_h_",
        "outputId": "4bf14fd9-7ae3-4dec-ad88-de1c0d34d915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "def nonlin(x,deriv=False):\n",
        "\tif(deriv==True):\n",
        "\t    return x*(1-x)\n",
        "\n",
        "\treturn 1/(1+np.exp(-x))\n",
        "\t\n",
        "data_in = np.array([[1, 0, 0, 0],\n",
        "            [0, 1, 0, 0],\n",
        "            [0, 0, 1, 0],\n",
        "            [0, 0, 0, 1],\n",
        "            [0, 0, 1, 0],\n",
        "            [0, 1, 0, 0]])\n",
        "                \n",
        "data_out = np.array([[0, 1, 0, 0],\n",
        "            [0, 0, 1, 0],\n",
        "            [0, 0, 0, 1],\n",
        "            [0, 0, 1, 0],\n",
        "            [0, 1, 0, 0],\n",
        "            [1, 0, 0, 0]])\n",
        "\n",
        "data_in=data_in/10\n",
        "data_out=data_out/10\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "alpha = 0.001\n",
        "mu = 0.0\n",
        "hidden_layers = 4\n",
        "\n",
        "weight_in = 2*np.random.random((4,hidden_layers)) - 1\n",
        "weight_hidden = 2*np.random.random((hidden_layers,4)) - 1\n",
        "\n",
        "\n",
        "feedback = np.zeros((len(data_in),hidden_layers))\n",
        "recurrence = 2*np.random.random((hidden_layers,hidden_layers))-1\n",
        "\n",
        "dataset = np.column_stack((data_in, feedback))\n",
        "weight_in = np.row_stack((weight_in, recurrence))\n",
        "\n",
        "\n",
        "old_change0 = np.zeros(weight_in.shape)\n",
        "old_change1 = np.zeros(weight_hidden.shape)\n",
        "\n",
        "for j in range(2000000):\n",
        "\n",
        "    layer_in = dataset\n",
        "    layer_hidden = nonlin(np.dot(layer_in,weight_in))\n",
        "    layer_out = nonlin(np.dot(layer_hidden,weight_hidden))\n",
        "\n",
        "    error_out = data_out - layer_out\n",
        "    \n",
        "    if (j% 100000) == 0:\n",
        "        print (\"Epoch:{} Error:{}\" .format(j, str(np.mean(np.abs(error_out)))))\n",
        "        \n",
        "    delta_out = error_out*nonlin(layer_out,deriv=True)\n",
        "    error_hidden = delta_out.dot(weight_hidden.T)\n",
        "    delta_hidden = error_hidden * nonlin(layer_hidden,deriv=True)\n",
        "\n",
        "    new_change0 = layer_in.T.dot(delta_hidden)\n",
        "    new_change1 = layer_hidden.T.dot(delta_out)\n",
        "\n",
        "    weight_hidden += mu * old_change1 + alpha * new_change1\n",
        "    weight_in += mu * old_change0 + alpha * new_change0\n",
        "\n",
        "    old_change1 = new_change1\n",
        "    old_change0 = new_change0\n",
        "    dataset = np.column_stack((dataset[:,0:4], layer_hidden))\n",
        "\n",
        "print (layer_out)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0 Error:0.45031590411389194\n",
            "Epoch:100000 Error:0.03878993210718985\n",
            "Epoch:200000 Error:0.03712522577281616\n",
            "Epoch:300000 Error:0.036624227311387876\n",
            "Epoch:400000 Error:0.03639619130557832\n",
            "Epoch:500000 Error:0.03627443773452596\n",
            "Epoch:600000 Error:0.036205260695931434\n",
            "Epoch:700000 Error:0.03616485602554741\n",
            "Epoch:800000 Error:0.03614091373945748\n",
            "Epoch:900000 Error:0.03612660310257308\n",
            "Epoch:1000000 Error:0.03611799768456854\n",
            "Epoch:1100000 Error:0.03611279609910725\n",
            "Epoch:1200000 Error:0.036109634017038254\n",
            "Epoch:1300000 Error:0.03610769711292677\n",
            "Epoch:1400000 Error:0.036106497349309784\n",
            "Epoch:1500000 Error:0.0361057415137268\n",
            "Epoch:1600000 Error:0.036105253179306594\n",
            "Epoch:1700000 Error:0.03610492609098126\n",
            "Epoch:1800000 Error:0.03610469621753782\n",
            "Epoch:1900000 Error:0.036104524956769406\n",
            "[[0.01707675 0.03323618 0.03385386 0.01656846]\n",
            " [0.01751601 0.03381676 0.03424943 0.01661029]\n",
            " [0.01661889 0.03259152 0.03272055 0.01582964]\n",
            " [0.01674087 0.03298209 0.03341739 0.01640389]\n",
            " [0.01661889 0.03259152 0.03272055 0.01582964]\n",
            " [0.01751601 0.03381676 0.03424943 0.01661029]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}